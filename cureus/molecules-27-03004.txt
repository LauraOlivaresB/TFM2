Citation: Feng, Y.-H.; Zhang, S.-W.
Prediction of Drug-Drug Interaction
Using an Attention-Based Graph
Neural Network on Drug Molecular
Graphs. Molecules 2022 ,27, 3004.
https://doi.org/10.3390/
molecules27093004
Academic Editors: Xing Chen and
Qi Zhao
Received: 10 April 2022
Accepted: 30 April 2022
Published: 7 May 2022
Publisher’s Note: MDPI stays neutral
with regard to jurisdictional claims in
published maps and institutional afﬁl-
iations.
Copyright: © 2022 by the authors.
Licensee MDPI, Basel, Switzerland.
This article is an open access article
distributed under the terms and
conditions of the Creative Commons
Attribution (CC BY) license (https://
creativecommons.org/licenses/by/
4.0/).
molecules
Article
Prediction of Drug-Drug Interaction Using an Attention-Based
Graph Neural Network on Drug Molecular Graphs
Yue-Hua Feng and Shao-Wu Zhang *
MOE Key Laboratory of Information Fusion Technology, School of Automation, Northwestern Polytechnical
University, Xi’an 710072, China; feng_yuehua@mail.nwpu.edu.cn
*Correspondence: zhangsw@nwpu.edu.cn
Abstract: The treatment of complex diseases by using multiple drugs has become popular. However,
drug-drug interactions (DDI) may give rise to the risk of unanticipated adverse effects and even
unknown toxicity. Therefore, for polypharmacy safety it is crucial to identify DDIs and explore their
underlying mechanisms. The detection of DDI in the wet lab is expensive and time-consuming,
due to the need for experimental research over a large volume of drug combinations. Although
many computational methods have been developed to predict DDIs, most of these are incapable of
predicting potential DDIs between drugs within the DDI network and new drugs from outside the
DDI network. In addition, they are not designed to explore the underlying mechanisms of DDIs and
lack interpretative capacity. Thus, here we propose a novel method of GNN-DDI to predict potential
DDIs by constructing a ﬁve-layer graph attention network to identify k-hops low-dimensional feature
representations for each drug from its chemical molecular graph, concatenating all identiﬁed features
of each drug pair, and inputting them into a MLP predictor to obtain the ﬁnal DDI prediction score.
The experimental results demonstrate that our GNN-DDI is suitable for each of two DDI predicting
scenarios, namely the potential DDIs among known drugs in the DDI network and those between
drugs within the DDI network and new drugs from outside DDI network. The case study indicates
that our method can explore the speciﬁc drug substructures that lead to the potential DDIs, which
helps to improve interpretability and discover the underlying interaction mechanisms of drug pairs.
Keywords: drug-drug interaction; prediction; feature representation; molecular graph; graph atten-
tion network
1. Introduction
Polypharmacy, also termed drug combination treatment, has become a promising
strategy for treating complex diseases (e.g., diabetes and cancer) in recent years [ 1]. For
example, Pembrolizumab has been combined with Sorafenib in the treatment of metastatic
hepatocellular carcinoma [ 2]. Entacapone increases the plasma concentration of Levodopa
and improves therapeutic effects on Parkinson’s disease [ 3]. Nevertheless, the combined
use of two or more drugs (i.e., drug-drug interactions, DDIs) triggers pharmacological
changes that may result in unexpected effects (e.g., side effects, adverse reactions, and even
serious toxicity) [ 4]. As the need for polypharmacy treatments increases, identiﬁcation of
DDIs has become urgent. Nevertheless, it is expensive and time-consuming to detect DDIs
among drug pairs on a large scale both in vitro and in vivo . To screen DDIs, computational
approaches, especially machine learning-based methods, have been developed to deduce
potential drug-drug interactions [5].
Existing computational approaches can be roughly classiﬁed into three categories: text-
mining-based, machine-learning-based, and deep-learning-based methods. Textmining-
based approaches discover and collect recorded DDIs from the scientiﬁc literature, elec-
tronic medical records [ 6,7], insurance claim databases, and the FDA Adverse Event Re-
porting System. They use Natural Language Processing (NLP) technology to extract DDI
Molecules 2022 ,27, 3004. https://doi.org/10.3390/molecules27093004 https://www.mdpi.com/journal/moleculesMolecules 2022 ,27, 3004 2 of 16
information from various formats of text, and they are very useful in building DDI-related
databases [ 7–13]. However, these approaches are incapable of detecting unrecorded DDIs,
and they cannot give an alert to potential drug interactions before drug combination
treatment [14].
With the advantages of both high efﬁciency and low costs, various machine learning
methods have been shown promise in providing preliminary screening of DDIs for further
experimental validation. Generally, models are trained by using conﬁrmed DDIs to infer
the potential DDIs among massive quantities of unlabeled drug pairs. The training involves
diverse drug properties, such as chemical structure [ 14–18], targets [ 14,15,18,19], anatomical
taxonomy [ 16,19,20], and phenotypic observation [ 17–20]. The models transform the DDI
prediction task that infers whether or not a drug interacts with another into a binary
classiﬁcation problem. These methods are usually implemented according to established
classiﬁers (e.g., KNN [ 16], SVM [ 16], logistic regression [ 14,20], decision tree [ 21], and naïve
Bayes [ 21]), network propagation of reasoning behind drug-drug network structures [ 20,22],
label propagation [ 23], random walk [ 15] and probabilistic soft logic [ 19,21], or matrix
factorization [ 17,18,24]. Generally, traditional machine learning methods rely heavily on
the quality of handcrafted features derived from the drug properties.
In terms of extracting features from data without manual input [ 25], deep learning
methods, especially graph convolution network methods, provide promising routes into
the ﬁeld of drug development and discovery [ 5], such as molecular activity prediction, drug
side effect prediction [ 17] drug target interactions prediction [ 25], drug response [ 26–29],
and drug synergy [30–34]. Those methods in the ﬁeld of drug-drug interaction prediction
contribute to traditional binary DDI prediction [ 35] or multi-type DDI prediction [36–39] .
Some of these methods have constructed deep learning frameworks to learn latent features
from various properties of drugs, and other methods have built models to extract the
latent features from the DDI network [ 40], including the homogeneous DDI network
and the heterogeneous knowledge network [ 41]. For example, NDD [ 42] calculated the
corresponding drug similarity matrix from several drug properties, and inputted it into a
multi-layer deep learning classiﬁer for predicting binary DDIs. Wang et al. [ 41] extracted
drug representation features by utilizing GCN from the DDI networks, and inputted them
into a three-layer multilayer perception (MLP) for predicting binary DDIs. KGNN [ 43]
constructed a drug knowledge graph that includes various entities such as drug target, side
effect, and pathway disease, and used the graph representation method to extract drug
features from this huge heterogeneous graph to predict DDIs. The methods [ 36–38] ﬁrst
treat the rows in a drug similarity matrix as corresponding drug feature vectors, and set
the concatenation of two feature vectors as the feature vector to represent a pair of drugs,
and then train a multi-layer DNN with feature vectors and types of DDIs as the classiﬁers
to predict multi-type DDIs.
Although these methods achieved inspiring results, they had several limitations as
follows. First, those methods extracting the latent features from the DDI network relied
on the network’s topological information, thus they are blind to new drugs that have no
links with the drugs in the DDI network. Secondly, current deep learning methods lack
interpretation of drug interactions, and it is difﬁcult to observe the underlying mechanisms
of drug interactions. To address these issues, here we propose a novel GNN-DDI method to
predict drug-drug interaction. GNN-DDI constructed a ﬁve-layer graph attention network
to identify k-hops low-dimensional feature representations for each drug from its chemical
molecular graph, and then concatenates the learned features for each drug pair, inputting
them into a MLP predictor to obtain the ﬁnal DDI prediction score. The multi-layer GAT
of CSGN-DDI can capture different kth-order substructure functional groups of the drug
molecular graph through multi-step operations, to generate effective feature representation
of the drugs. The experimental results demonstrate that our GNN-DDI is superior in
predicting the potential DDIs between the drugs within the DDI network and new drugs
outside the DDI network. GNN-DDI helps to improve interpretability and reveal the
underlying mechanisms of drug pair interactions.Molecules 2022 ,27, 3004 3 of 16
2. Materials and Methods
2.1. Datasets
We ﬁrst built the DDI dataset that contains 1,935 drugs and 589,827 annotated drug-
drug interactions from DrugBank 5.0 [ 44]. Then we downloaded the completed XML-
formatted database (including the comprehensive proﬁles of 11,440 drugs), and parsed all
approved small-molecule drugs and their DDI entries. We extracted the drugs’ chemical
structure information using Simpliﬁed Molecular Input Line Entry System (SMILES) strings
from the XML ﬁle provided by DrugBank, and transformed them into the corresponding
molecular structure graph using the open-source library RDKit (Figure 1). These drug
molecular graphs were taken as the input graphs for the graph convolutional network in
the feature extractor of GNN-DDI to obtain the drug feature vectors. In each molecular
graph, atoms were denoted as nodes, edges representing the bond between atoms, and
each node containing a 78-dim initial feature vector including the symbol of the atom
(i.e., 44-dimension, one-hot code), the number of adjacent atoms, the implied valence of the
atom, its formal charge, the number of free radical electrons, the hybridization of the atom
(i.e., 5-dimension, one hot code), the number of hydrogen bonds, and whether the atom
is aromatic.
Molecules 2022 , 27, x FOR PEER REVIEW 3 of 17 
 
 network and new drugs outside the DDI netw ork. GNN-DDI helps to improve interpret-
ability and reveal the underlying mechanisms of drug pair interactions. 
2. Materials and Methods  
2.1. Datasets 
We first built the DDI dataset that contains 1,935 drugs and 589,827 annotated drug-
drug interactions from DrugBank 5.0 [44]. Then we downloaded the completed XML-for-
matted database (including the comprehensive profiles of 11,440 drugs), and parsed all 
approved small-molecule drugs and their DDI entries. We extracted the drugs’ chemical 
structure information using Simplified Molecular Input Line Entry System (SMILES) 
strings from the XML file provided by DrugBank, and transformed them into the corre-
sponding molecular structure graph using the open-source library RDKit (Figure 1). These 
drug molecular graphs were taken as the in put graphs for the graph convolutional net-
work in the feature extractor of GNN-DDI to ob tain the drug feature vectors. In each mo-
lecular graph, atoms were denoted as nodes, edges representing the bond between atoms, 
and each node containing a 78-dim initial feature vector including the symbol of the atom 
(i.e., 44-dimension, one-hot code), the number of adjacent atoms, the implied valence of the atom, its formal charge, the number of fr ee radical electrons, the hybridization of the 
atom (i.e., 5-dimension, one hot code), the number of hydrogen bonds, and whether the 
atom is aromatic. 
GNN-DDI learns the drug representation features directly from their chemical mo-
lecular structure graphs by graph convolution network. In order to compare those fea-
tures with other molecular structure fingerprint features and features from their biological 
properties, we also extracted the ATC (Anato mical Therapeutic Chemical Classification) 
and DBP (Drug Binding Proteins) from DrugBa nk, and utilized the PubChem fingerprint 
and the MACCSkeys fingerprint (Molecular ACCess System keys fingerprint [45] to con-
vert the SMILES of drugs into the 881-dimesi on and 166-dimension binary vector, respec-
tively. Each bit in the vector indicates the occurrence or non-occurrence of a pre-defined 
substructure according to Pubchem fingerpr ints or MACCSkeys fi ngerprints. ATC codes 
are released by the World Health Organization  [46], and they categorize drug substances 
at different levels according to organs they affect, application area, therapeutic properties, 
chemical, and pharmacological properties. It is generally accepted that compounds with 
similar physicochemical properties exhibit similar biological activity. To feed the 7-bit 
ATC code into a deep learning model, we converted the data into a one-hot code with 118 
bits. We also used drug-binding protein (DBP ) data [47], containing 899 drug targets and 
222 non-target proteins . Similarly, each drug was repres ented as a binary DBP-based fea-
ture vector, with each bit indicating whet her the drug binds to a specific protein. 
 
Figure 1. Drug molecular graph transformed from drug SMILES. 
Figure 1. Drug molecular graph transformed from drug SMILES.
GNN-DDI learns the drug representation features directly from their chemical molecu-
lar structure graphs by graph convolution network. In order to compare those features with
other molecular structure ﬁngerprint features and features from their biological properties,
we also extracted the ATC (Anatomical Therapeutic Chemical Classiﬁcation) and DBP
(Drug Binding Proteins) from DrugBank, and utilized the PubChem ﬁngerprint and the
MACCSkeys ﬁngerprint (Molecular ACCess System keys ﬁngerprint [ 45] to convert the
SMILES of drugs into the 881-dimesion and 166-dimension binary vector, respectively. Each
bit in the vector indicates the occurrence or non-occurrence of a pre-deﬁned substructure
according to Pubchem ﬁngerprints or MACCSkeys ﬁngerprints. ATC codes are released
by the World Health Organization [ 46], and they categorize drug substances at different
levels according to organs they affect, application area, therapeutic properties, chemical,
and pharmacological properties. It is generally accepted that compounds with similar
physicochemical properties exhibit similar biological activity. To feed the 7-bit ATC code
into a deep learning model, we converted the data into a one-hot code with 118 bits. We also
used drug-binding protein (DBP) data [ 47], containing 899 drug targets and 222 non-target
proteins. Similarly, each drug was represented as a binary DBP-based feature vector, with
each bit indicating whether the drug binds to a speciﬁc protein.
2.2. Problem Formulation
LetGbe(n+m)drugs including nknown drugsG1=fdigand mnew drugs
G2=
dj	
, whereG1[G 2=GandG1\G 2=?, andD1=
Gx, Gy	
sis the interac-
tion between GxeG1and GyeG1, andD2=fGx, Gzgis the interaction between GxeG1andMolecules 2022 ,27, 3004 4 of 16
GzeG2. In addition, each drug can be represented as a molecular structure graph, and we
denote it by a graph Gi(Vi,Ei), where Vi=
Vi1,Vi2, . . . , Vip	
is the set of nodes represent-
ing the atoms in the drug di,Ei=f(Vis,Vit)p
s,t=1gis the set of edges representing the bonds
connecting two atoms in the drug di, and H(0)
i= (h(0)
i1, h(0)
i2, . . . , h(0)
ip)T
is the initial feature
matrix of p nodes in Giof drug di. Our task is to deduce DDI candidates among those
unannotated drug-drug pairs based on known DDIs. There are two different scenarios of
DDI prediction as follows:
The ﬁrst prediction task is to learn a function mapping F:G1G 1!f0, 1gto deduce
the potential interactions among the unlabeled pairs of drugs in G1(Figure 2A).
Molecules 2022 , 27, x FOR PEER REVIEW 4 of 17 
 
 2.2. Problem Formulation 
Let 𝒢 be (𝑛 + 𝑚)  drugs including n known drugs 𝒢ଵ={𝑑௜} and m new drugs 𝒢ଶ=
൛𝑑௝ൟ, where 𝒢ଵ∪𝒢 ଶ=𝒢 and 𝒢ଵ∩𝒢 ଶ=∅, and 𝒟ଵ={ G ୶,G୷}s is the interaction between 
G୶ϵ𝒢ଵ and G୷ϵ𝒢ଵ , and 𝒟ଶ={ G ୶,G୸} is the interaction between G୶ϵ𝒢ଵ and G୸ϵ𝒢ଶ. In addi-
tion, each drug can be represented as a molecular structure graph, and we denote it by a 
graph G௜(𝑉௜,𝐸௜), where V௜={ 𝑉 ௜ଵ,𝑉௜ଶ,…,𝑉 ௜௣} is the set of nodes representing the atoms in 
the drug d୧, 𝐸௜= { ( 𝑉 ௜௦,𝑉௜௧)ୱ,୲ୀଵ୮} is the set of edges representing the bonds connecting two 
atoms in the drug d୧, and H୧(଴)=( h୧ଵ(଴),h୧ଶ(଴),…,h୧୮(଴))୘ is the initial feature matrix of p nodes 
in G௜ of drug d୧. Our task is to deduce DDI candidates among those unannotated drug-
drug pairs based on known DDIs. There are two different scenarios of DDI prediction as 
follows:  
The first prediction task is to learn a function mapping ℱ: 𝒢 ଵ×𝒢 ଵ→ {0,1}  to deduce 
the potential interactions among the unlabeled pairs of drugs in 𝒢ଵ (Figure 2A). 
The second prediction task is to learn a function mapping ℱ: 𝒢 ଵ×𝒢 ଶ→ {0,1}  to de-
duce the potential interactions amon g the unlabeled drug pairs between 𝒢ଵ and 𝒢ଶ (Figure 
2B). We used all known DDIs ൛G୶,G୷ൟ∈𝒟 ଵ|G୶∈𝒢 ଵ 𝑎𝑛𝑑 G ୷∈𝒢 ଵ to train the prediction 
model for predicting all unlabeled drug pairs ൛G୶,G୷ൟ∈𝒟 ଶ|G୶∈𝒢 ଵ 𝑎𝑛𝑑 G ୷∈𝒢 ଶ. 
 
Figure 2. Two scenarios of DDI prediction. ( A) DDI prediction among drugs in the DDI network ( B) 
DDI prediction between the drugs within the DDI  network and new drugs outside the network.  
2.3. GNN-DDI Model 
In this work, we propose a representation learning framework, GNN-DDI, to predict 
drug-drug interactions. GNN-DDI mainly consists of two modules: a drug feature extrac-
tor and a DDI predictor (Figure 3). The first module is composed of a five-layer graph 
attention convolutional network (GAT) [48] that learns the function 𝑓௘(G௜) to obtain the 
latent feature vector 𝑍௜ of each drug from its molecular structure graph G௜(𝑉௜,𝐸௜), where 
𝑍௜∈𝑅ଵ×௞. The latent vectors ( 𝑍௜ and 𝑍௝) of two drugs are concatenated to form the feature 
vector 𝑍௜௝ of the corresponding drug pair. In each  layer of the feature extractor, the con-
volutional operation aggregates information from its atomic neighborhood and updates 
the node feature for each atomic node in a drug molecular structure graph. Through sev-
eral convolutional layers, informative features of drug chemical functional groups within 
its whole chemical structure are captured, that are critical in drug interactions. The second 
module is a multi-layer perception that predicts the probability score of drug pair inter-
action by taking the feature vector 𝑍௜௝ of the drug pair as the input. The overall algorithm 
of GNN-DDI is shown in Algorithm 1. 
Algorithms 1 The pseudo-code of GNN-DDI. 
  
Figure 2. Two scenarios of DDI prediction. ( A) DDI prediction among drugs in the DDI network
(B) DDI prediction between the drugs within the DDI network and new drugs outside the network.
The second prediction task is to learn a function mapping F:G1G 2!f0, 1gto
deduce the potential interactions among the unlabeled drug pairs between G1andG2
(Figure 2B). We used all known DDIs
Gx, Gy	2D 1Gx2G 1andGy2G 1to train the pre-
diction model for predicting all unlabeled drug pairs
Gx, Gy	2D 2Gx2G 1andGy2G 2.
2.3. GNN-DDI Model
In this work, we propose a representation learning framework, GNN-DDI, to predict
drug-drug interactions. GNN-DDI mainly consists of two modules: a drug feature extractor
and a DDI predictor (Figure 3). The ﬁrst module is composed of a ﬁve-layer graph attention
convolutional network (GAT) [ 48] that learns the function fe(Gi)to obtain the latent feature
vector Ziof each drug from its molecular structure graph Gi(Vi,Ei), where Zi2R1k. The
latent vectors ( ZiandZj) of two drugs are concatenated to form the feature vector Zijof the
corresponding drug pair. In each layer of the feature extractor, the convolutional operation
aggregates information from its atomic neighborhood and updates the node feature for each
atomic node in a drug molecular structure graph. Through several convolutional layers,
informative features of drug chemical functional groups within its whole chemical structure
are captured, that are critical in drug interactions. The second module is a multi-layer
perception that predicts the probability score of drug pair interaction by taking the feature
vector Zijof the drug pair as the input. The overall algorithm of GNN-DDI is shown in
Algorithm 1.Molecules 2022 ,27, 3004 5 of 16
Molecules 2022 , 27, x FOR PEER REVIEW 5 of 17 
 
 Algorithms 1  The pseudo-code of GNN-DDI 
input: Molecular graph G୶ of drug x and its original features H୧(଴) of atomic nodes 
Molecular graph G୷ of drug y and its original features H୧(଴) of atomic nodes  
output: Probability score 𝑝(G ୶,G୷) of drug pair (x, y)  
1: Initialize parameter sets in GNN-DDI. 
2: for k in K: 
3: Compute h୶(୩ାଵ)and  h୷(୩ାଵ) based on Equation (1 ) to Equation (3). 
4: SAGPooling based on Equation (4) to obtain Hୋ౮(୩ାଵ) and H୷(୩ାଵ) in layer k. 
5: end for 
6: Concatenate k-hops  Hୋ౮(୩ାଵ) and H୷(୩ାଵ) based on Equation (5) to obtain Hୋ౮ and Hୋ౯. 
7: Concatenate Hୋ౮ and Hୋ౯ to obtain the latent feature vector of a drug pair H(G ୶,G୷) 
8: Feed feature vector H(G ୶,G୷) into the predictor to get probability score 𝑝(G ୶,G୷). 
 
Figure 3. Overall framework of GNN-DDI. ( A) drug feature extractor. Th e five-layer GAT networks 
are built to encode the molecular structure graph of each drug into its feature vectors H୧(୩)=
(h୧ଵ(௞),h୧ଶ(୩),…,h୧୮(୩))୘, to capture topological properties especi ally chemical functi onal groups within 
the whole chemical structure graph,  which are critical in drug interactions. In addition, the atomic 
nodes feature vectors H୧(୩) in the molecular graph output from each layer are transformed to drug 
feature Hୋ౟(୩) by SAGPooling in each layer, and those drug features Hୋ౟(୩) are concatenated together as 
final drug feature vector 𝑍ୋ౟. (B) DDI predictor. Concatenatin g two drug latent features 𝑍ୋ౟and 𝑍ୋౠ 
to feed into a MLP for implem enting the prediction task. 
2.3.1. Feature Extractor 
Each drug has its molecular structure graph, in which atoms are denoted as nodes, 
and edges represent the bonds between atoms. Because the numbers of atoms and chem-
ical bonds in the molecular graph of each drug are different, each molecular graph can be 
learned by the graph convolutional network to  generate drug informative representation. 
The graph convolutional network consists of an information aggregation function and an 
update function. The former continuously gathers neighborhood information for each 
node in the graph, and the latter updates the gathered information to obtain the informa-
tive representation features for each node.  
The traditional convolution network aggregates the neighborhood information of 
each node in the molecular graph without difference. Due to the different importance of 
neighbor nodes, the weighted aggregation ca n obtain more effective representations for 
Figure 3. Overall framework of GNN-DDI. ( A) drug feature extractor. The ﬁve-layer GAT
networks are built to encode the molecular structure graph of each drug into its feature vec-
tors H(k)
i=
h(k)
i1, h(k)
i2, . . . , h(k)
ipT
, to capture topological properties especially chemical functional
groups within the whole chemical structure graph, which are critical in drug interactions. In addition,
the atomic nodes feature vectors H(k)
iin the molecular graph output from each layer are transformed
to drug feature H(k)
Giby SAGPooling in each layer, and those drug features H(k)
Giare concatenated
together as ﬁnal drug feature vector ZGi. (B) DDI predictor. Concatenating two drug latent features
ZGiand ZGjto feed into a MLP for implementing the prediction task.
Algorithms 1 The pseudo-code of GNN-DDI.
Algorithms 1 The pseudo-code of GNN-DDI
input: Molecular graph G xof drug x and its original features H(0)
iof atomic nodes
Molecular graph G yof drug y and its original features H(0)
iof atomic nodes
output: Probability score p 
Gx, Gy
of drug pair (x, y)
1: Initialize parameter sets in GNN-DDI.
2: for k in K:
3: Compute h(k+1)
x and h(k+1)
y based on Equations (1) to (3).
4: SAGPooling based on Equation (4) to obtain H(k+1)
Gxand H(k+1)
y in layer k.
5: end for
6: Concatenate k-hops H(k+1)
Gxand H(k+1)
y based on Equation (5) to obtain H Gxand H Gy.
7: Concatenate H Gxand H Gyto obtain the latent feature vector of a drug pair H (Gx, Gy)
8: Feed feature vector H (Gx, Gy)into the predictor to get probability score p 
Gx, Gy
.
2.3.1. Feature Extractor
Each drug has its molecular structure graph, in which atoms are denoted as nodes,
and edges represent the bonds between atoms. Because the numbers of atoms and chemical
bonds in the molecular graph of each drug are different, each molecular graph can be
learned by the graph convolutional network to generate drug informative representation.
The graph convolutional network consists of an information aggregation function and an
update function. The former continuously gathers neighborhood information for each node
in the graph, and the latter updates the gathered information to obtain the informative
representation features for each node.
The traditional convolution network aggregates the neighborhood information of
each node in the molecular graph without difference. Due to the different importanceMolecules 2022 ,27, 3004 6 of 16
of neighbor nodes, the weighted aggregation can obtain more effective representations
for drugs and be conductive to disclosing drug interaction mechanisms. Therefore, we
designed a ﬁve-layer graph convolutional network with an attention mechanism [ 48,49] to
generate the embedding representation for each atomic node in the drug molecular graph.
Each node is represented as a latent feature vector, which contains the information about
its neighborhood in the drug molecular graph without manual feature engineering.
(A) Information aggregation and update
In each layer of the feature extractor, the convolutional operation aggregated informa-
tion by weighting from its atomic neighborhood and updated the node feature for each
atomic node in a drug molecular structure graph. Through several convolutional layers,
we captured informative features of drug chemical functional groups within each drug’s
whole chemical structure, that are critical in drug interactions.
For any layer in the GNN-DDI feature extractor (Figure 2A), the general propagation
rule is deﬁned as:
h(k+1)
i=s(åj2NiaijW(k)h(k)
j+W(k)h(k)
i) (1)
where Nidenotes the set of atomic node neighbors in Gx,h(k)
iis the input feature vector, h(0)
i
is the original features of each atomic node in molecular graph (details in Section 2.1), W(k)is
the trainable weight matrix in the k-th layer of Gx,sis a non-linear element-wise activation
function (i.e., ReLU), and aijdenotes the aggregation weight between the updating node
vxiand its neighborhood node vxjdetermining the relevant importance between them. aij
can be calculated by the attention mechanism as follows:
aij=so f tmax 
eij=exp 
eij
åk2Niexp(eik)(2)
eij=LeakyReLU (!aT[watth(k)
ikwatth(k)
j
(3)
where!aT2R2F0is a shared weight vector composed of a layer of feedforward neural
network, Tis a transpose operation, LeakyReLU is an activation function [ 50], andk
denotes the concatenated operation.
(B) Pooling of atomic feature vectors
The feature extractor takes the molecular structure graph and atomic original features
of each drug as input, to output the latent feature vector Zof each drug using a multi-layer
graph convolution network. In each layer, the neighborhood information of each atomic
node vxiin drug molecular graph Gxis continuously aggregated to update the feature h(k)
i
of node vxi, hence an updated feature vector matrix H(k)
i2Rpkof each atom in drug Gxis
obtained, here pis the number of atoms in drug Gxand k is the dimension of this layer. The
feature matrix is taken as input to the next layer of the feature extractor module. To predict
interactions among drug pairs, the feature matrix H(k)
iof the drug molecular graph must
be transformed into the drug feature vector H(k)
Gi. Therefore, after convolutional operations
in each layer, we adopted SAGPooling [49] to implement this transform operation:
H(k)
Gi=ån
iih(k)
i(4)
where iis the feature weight of each atomic node vxiin the whole molecular graph Gx,
which represents the importance of each node in the molecular graph. iis determined
according to the topological and contextual information of node v xiby SAGPooling.
As the learned representation features are drawn from different multi-head attention
in different subspaces, the multi-head attention mechanism can improve the model’s
learning stability and enhance its expression ability [ 51]. Therefore, we adopted multi-head
attention in the feature extractor. Assuming Lheads are adopted, in each layer of the feature
extractor, there are Linformation aggregation and update operations from Equations (1)–(3)Molecules 2022 ,27, 3004 7 of 16
in parallel, and Lsame dimension representation features of each node are obtained. Then
they are concatenated together as the ﬁnal feature h(k)
i.
2.3.2. Feature Aggregation for Drug Pairs
So far, ﬁve k-hop latent feature vectors H(k)
Gxof each drug were obtained from ﬁve-layer
GAT. Different k-hops of feature vectors involve various neighbor receptive ﬁelds, therefore
they contain various sizes of sub-structures in a drug molecular graph. For example, the
molecular chemical structure graphs of two drugs Hydroquinone (DrugBank ID: DB09526)
and Acetic acid (DrugBank ID: DB03166) are shown in Figure 4 respectively. They are both
weak acids due to the sub-structures of phenolic hydroxyl AROH and carboxyl COOH.
Molecules 2022 , 27, x FOR PEER REVIEW 7 of 17 
 
 feature extractor, there are  L information aggregation and update operations from Equa-
tions (1)–(3) in parallel, and L same dimension representation  features of each node are 
obtained. Then they are concatenated together as the final feature h୧(୩). 
2.3.2. Feature Aggregation for Drug Pairs  
So far, five k-hop latent feature vectors Hୋ౮(୩) of each drug were obtained from five-
layer GAT. Different k-hops of feature vector s involve various neighbor receptive fields, 
therefore they contain various sizes of sub-st ructures in a drug molecular graph. For ex-
ample, the molecular chemical structure graphs of two drugs Hydroquinone (DrugBank 
ID: DB09526) and Acetic acid (DrugBank ID: DB 03166) are shown in Figure 4 respectively. 
They are both weak acids due to the sub-stru ctures of phenolic hydroxyl AROH and car-
boxyl COOH.  
In order to correctly extract the sub-stru cture ArOH in hydroquinone, we need a 
three-hop information aggregation from the neighborhoods in its molecular graph. In the 
same way, we only need a two-hop convolution operation to correctly extract the sub-
structures COOH from Acetic acid. However, traditional graph representation networks usually use a fixed-sized receptive field (i.e., using the final feature vectors from the last 
layer of graph convolution network for downst ream tasks), which may result in either 
incomplete sub-structures being extracted (i.e., receptive fields are too small), or redun-
dant sub-structures being included (i.e., recept ive fields are too large). In order to solve 
this limitation, all five k-hop latent feature vectors H
ୋ౮(୩) of each drug were concatenated as 
the final representation feature of the drug for the downstream prediction task. 
𝑍ୋ౮=∥௞ୀଵ௄Hୋ౮(୩)  (5)
where ∥ denotes the concatenated operation. 
Finally, we concatenated the latent feature vectors of two drugs in each drug pair to 
form a feature vector ℎ൫G ୶,G୷൯=[ 𝑍 ୋ౮,𝑍ୋ೤] to represent the drug pair, and took ℎ൫G ୶,G୷൯ 
as the input of MLP to predict the probability value of interaction between two drugs. 
 
Figure 4. Examples of receptive fields with k-hop convolution network. 
2.3.3. MLP Predictor 
GNN-DDI converts the DDI prediction task in to a binary classification problem. Be-
cause MLP has been proved to give excellent performance in classification, we constructed 
Figure 4. Examples of receptive ﬁelds with k-hop convolution network.
In order to correctly extract the sub-structure ArOH in hydroquinone, we need a
three-hop information aggregation from the neighborhoods in its molecular graph. In the
same way, we only need a two-hop convolution operation to correctly extract the sub-
structures COOH from Acetic acid. However, traditional graph representation networks
usually use a ﬁxed-sized receptive ﬁeld (i.e., using the ﬁnal feature vectors from the last
layer of graph convolution network for downstream tasks), which may result in either
incomplete sub-structures being extracted (i.e., receptive ﬁelds are too small), or redundant
sub-structures being included (i.e., receptive ﬁelds are too large). In order to solve this
limitation, all ﬁve k-hop latent feature vectors H(k)
Gxof each drug were concatenated as the
ﬁnal representation feature of the drug for the downstream prediction task.
ZGx=kK
k=1H(k)
Gx(5)
wherekdenotes the concatenated operation.
Finally, we concatenated the latent feature vectors of two drugs in each drug pair to
form a feature vector h 
Gx, Gy= [ZGx,ZGy]to represent the drug pair, and took h 
Gx, Gy
as the input of MLP to predict the probability value of interaction between two drugs.
2.3.3. MLP Predictor
GNN-DDI converts the DDI prediction task into a binary classiﬁcation problem. Be-
cause MLP has been proved to give excellent performance in classiﬁcation, we constructed
a ﬁve-layer MLP as the predictor (Figure 3). ReLU was selected as the activation functionMolecules 2022 ,27, 3004 8 of 16
in the ﬁrst four layers, while the activation function SoftMax was selected in the last layer,
which maps the output score into the range of 0–1, representing how likely potential DDIs
are in drug pairs.
In the GNN-DDI training process, the binary cross-entropy loss function was adopted
to continuously optimize the model.
L(p,q)= åi,jyijlog 
p 
Gx, Gy+ 
1 yij(1 log 
p 
Gx, Gy
(6)
where yijis the true label (i.e., 0 or 1) of the training drug pair 
Gx, Gy
,p 
Gx, Gy
is
the predicting probability value generated by the MLP predictor. Through continuous
reduction of the loss function, the model is optimized.
2.4. Cross-Validation Strategy and Assessment Metrics
In order to evaluate the performance of GNN-DDI, we employed two different cross-
validation strategies of sample set partition. The ﬁrst one is the edge set partition strategy,
in which all interaction edges were randomly partitioned into 80% training edges (which
includes 5% validation edges) and 20% test edges. The other one is the drug partition
strategy, in which all drugs were randomly partitioned into 80% training drugs and 20%
test drugs. As shown in Figure 5A, the edge set A was the training set and the edge set B
was the test set in the edge partition strategy. However, in the drug partition strategy, as
the interactions between drugs in the training set and in the test set were deleted, the drugs
in the test set are regarded as new drugs. Meanwhile, those new drugs did not appear in
the training process, which was completely new to the model. Therefore, the interactions
among training drugs were taken as the training samples, and the interactions between
new drugs and training drugs as the test samples. For example, as shown in Figure 5B,
drugs d1 to d5 were the training drugs and d6 to d8 were the test drugs. All edges (in set
A set) between the training drugs were used as the training samples, and all edges (in set
B) between the training drugs and the test drugs were used as the test samples. The drug
partition strategy can measure the performance of a predictor when new drugs appear. All
the strategies were repeated 10 times, and the average results were used to evaluate the
prediction performance of GNN-DDI.
Molecules 2022 , 27, x FOR PEER REVIEW 8 of 17 
 
 a five-layer MLP as the predictor (Figure 3). ReLU was selected as the activation function 
in the first four layers, while the activation function SoftMax was selected in the last layer, 
which maps the output score into the range of  0–1, representing how likely potential DDIs 
are in drug pairs.  
In the GNN-DDI training process, the binary cross-entropy loss function was 
adopted to continuously optimize the model. 
𝐿(𝑝, 𝑞)= − ∑ 𝑦௜௝ log (𝑝(G ୶,G୷)) + (1 − 𝑦 ௜௝)(1 − log (𝑝(G ୶,G୷)) ௜,௝   (6)
where 𝑦௜௝ is the true label (i.e., 0 or 1) of the training drug pair (G୶,G୷), 𝑝(G ୶,G୷) is the 
predicting probability value generated by the MLP predictor. Through continuous reduc-
tion of the loss function, the model is optimized. 
2.4. Cross-Validation Strategy and Assessment Metrics 
In order to evaluate the performance of GNN-DDI, we employed two different cross-
validation strategies of sample set partition. The first one is the edge set partition strategy, 
in which all interaction edges were randomly partitioned into 80% training edges (which 
includes 5% validation edges) and 20% test edges. The other one is the drug partition 
strategy, in which all drugs were randomly partitioned into 80% training drugs and 20% 
test drugs. As shown in Figure 5A, the edge set A was the training set and the edge set B 
was the test set in the edge partition strategy.  However, in the drug partition strategy, as 
the interactions between drugs in the training  set and in the test set were deleted, the 
drugs in the test set are regarded as new drugs. Meanwhile, those new drugs did not 
appear in the training process, which was co mpletely new to the model. Therefore, the 
interactions among training drugs were taken as  the training samples, and the interactions 
between new drugs and training drugs as the test samples. For example, as shown in Fig-ure 5B, drugs d1 to d5 were the training drugs and d6 to d8 were the test drugs. All edges 
(in set A set) between the training drugs were used as the training samples, and all edges 
(in set B) between the training drugs and the test drugs were used as the test samples. The 
drug partition strategy can measure the performance of a predictor when new drugs ap-
pear. All the strategies were repeated 10 times, and the average results were used to eval-uate the prediction performance of GNN-DDI.  
 
Figure 5. Two cross-validation strategies of sample partitioning. ( A) Edge partition strategy, ( B) 
Drug partition strategy. 
Accuracy (ACC), precision, recall, F1 score, AUC (i.e., area under the receiver oper-
ating characteristic curve), and AUPR (i.e., area under the precision-recall curve) were 
used to assess the performance of GNN-DDI. The receiver operating characteristic curve 
Figure 5. Two cross-validation strategies of sample partitioning. ( A) Edge partition strategy, ( B) Drug
partition strategy.Molecules 2022 ,27, 3004 9 of 16
Accuracy (ACC), precision, recall, F1 score, AUC (i.e., area under the receiver operating
characteristic curve), and AUPR (i.e., area under the precision-recall curve) were used to
assess the performance of GNN-DDI. The receiver operating characteristic curve reveals
the relationship between true-positive rate (precision) and false-positive rate based on
various thresholds. The precision-recall curve reveals the relationship between precision
(true-positive rate) and recall based on various thresholds. These metrics are deﬁned
as follows:
Accuracy =TP+TN
TP+FP+TN+FN(7)
Precision =TP
TP+FP(8)
Recall =TP
TP+FN(9)
F1=2PrecisionRecall
Precision +Recall(10)
where TP,FP,TN, and FNrefer to the numbers of true positive samples, false positive
samples, true negative samples, and false negative samples, respectively.
3. Results and Discussion
In this section, we ﬁrst introduce the GNN-DDI hyper-parameters, then compare
the performance of GNN-DDI with other existing methods in both DDI prediction sce-
narios. We also demonstrate the effectiveness of structural features learned by using the
feature extractor in GNN-DDI. Finally, through a case study we investigate the respective
substructures of a drug pair leading to a potential DDI.
3.1. Parameter Setting
To learn an optimal model of DDI prediction, we ﬁrst determined the architecture of
GNN-DDI. The model consisted of 5 layers of attention-mechanism-based graph convo-
lution network in which each layer had 2 attention heads. The feature dimension of each
head was 32-dimension (32-dim), so the total feature dimension of each layer was 64-dim.
The drug feature dimension outputted from the feature extractor was 320 ( 645), thus the
number of neurons in the input layer of the MLP predictor was 640 (i.e., the dimension of a
drug pair). The dimension of the other three hidden layers was determined empirically. The
numbers of neurons in each of the three hidden layers were 128, 64, and 32, respectively.
With this feature extractor architecture and the MLP predictor, we performed a grid
search with an Adam optimizer [ 52] to tune the hyper-parameters (i.e., epoch, learning
rate, and batch size) of GNN-DDI. The epoch (i.e., the number of training iterations) was
tuned from the list of values {20, 60,100, 200, 400, 600, 1000}. The learning rate (determining
whether and when the objective function converges to the optimal values) was empirically
investigated from the list {0.0001, 0.001, 0.005, 0.01, 0.05, 0.1}. The mini-batch strategy
(i.e., sampling a ﬁxed number of drug pairs in each batch) was tuned from the list {50, 200,
400, 600, 1000, 2000}. We ﬁnally experimentally determined a well-trained GNN-DDI by
setting the epoch at 400, the learning rate at 0.001, and the batch size at 1024.
3.2. Results of GNN-DDI and Five Other Methods in the First Prediction Scenario
To validate the performance of GNN-DDI in the ﬁrst prediction scenario (i.e., pre-
dicting the interactions of drugs within the DDI network), we compared our GNN-DDI
method with other ﬁve state-of-the-art methods: two of Vilar’s methods (named as Vilar 1
and Vilar 2, respectively) [ 53,54], the label propagation-based method (LP) [ 23], Zhang’s
method [ 15] and DPDDI [ 22]. Vilar 1 [ 53] identiﬁed potential DDIs by integrating a Tani-
moto similarity matrix of molecular structures with the known DDI matrix through a linear
matrix transformation. Vilar 2 [ 54] used drug interaction proﬁle ﬁngerprints (IPFs) to mea-
sure similarity for predicting DDIs. The LP method [ 23] applied label propagation to assignMolecules 2022 ,27, 3004 10 of 16
labels from known DDIs to previously unlabeled nodes by computing drug-similarity-
derived weights of edges within the DDI network. Zhang’s method [ 15] collected a variety
of drug-related data (e.g., known drug-drug interactions, drug substructures, targets, en-
zymes, transporters, pathways, indications, and side effects) to build 29 base classiﬁers
(i.e., KNN, random walk, matrix disturbed method, etc.), then developed a classiﬁer ensem-
ble model to predict DDIs. DPDDI [ 22] constructed a graph convolution network to learn
the network structure features of drugs from the DDI network for predicting potential drug
interactions within the DDI network. In this section, all comparing methods used the edge
partition strategy to split the DDI edges into training edges and test edges.
The comparison results of GNN-DDI against the ﬁve other methods are shown in
Table 1, from which we can see that GNN-DDI achieved the best results. It outperformed
four other state-of-the-art methods in terms of AUPR, Recall, Precision and F 1. GNN-DDI
achieved improvements of 8.5~22.9%, 8.9~66.8%, 13.2~42.5%, 9.4~57%, and 11.8~53.5%
against the Vilar 1, Vilar 2, LP , and Zhang methods in terms of AUPR, recall, precision,
ACC, and F1 score, respectively.
Table 1. Results of GNN-DDI and other ﬁve methods in the ﬁrst prediction scenario.
Methods AUC AUPR Recall Precision ACC F1
Vilar 1 [53] 0.707 0.262 0.495 0.253 0.719 0.334
Vilar2 [54] 0.826 0.533 0.569 0.515 0.862 0.540
LP [23] 0.851 0.799 0.685 0.729 0.809 0.706
Zhang [15] 0.954 0.841 0.788 0.717 0.934 0.751
DPDDI 0.956 0.907 0.810 0.754 0.940 0.840
GNN-DDI 0.936 0.930 0.920 0.823 0.863 0.869
Although the AUC of our GNN-DDI was little lower than that of DPDDI and Zhang’s
method, and the ACC of our GNN-DDI was lower than that of DPDDI, the performance
results in terms of AUPR, recall, precision, and F 1for GNN-DDI are higher than that for
DPDDI and Zhang’s method. Zhang’s method used nine drug-related data sources, while
GNN-DDI used only the drug molecular graph. More importantly, Zhang’s method and
DPDDI can only work in the ﬁrst DDI prediction scenario, that is, they predict only the
interactions between known drugs, and cannot predict the interactions between known
drugs and new drugs (i.e., the second DDI prediction scenario).
3.3. Results of GNN-DDI and Four Other Methods in the Second Prediction Scenario
In this section, we evaluated the performance of GNN-DDI in the second DDI predic-
tion scenario (i.e., predicting the interactions between known drugs and new drugs) by
using the drug partition strategy to split the drugs in the DDI network into the training
drugs and testing drugs. The new drugs did not appear in the training process. Therefore,
the drug partition strategy is able to measure the performance of prediction methods
when new drugs appear. We compared our GNN-DDI method with other four different
chemical- and biological-feature-based prediction methods. These four compared meth-
ods include two chemical-structure feature-based methods (the PubChem feature-based
method and the MACCSkeys feature-based method), the ATC feature-based method, and
the DBP feature-based method. The DBP method extracted 3334-dim structure features,
and the ATC method extracted 118-dim structure features. The PubChem feature-based
method extracted 881-dim features from the PubChem ﬁngerprint, and the MACCSkeys
feature-based method extracted 166-dim features from the MACCSkeys ﬁngerprint. These
molecular structure features derived from GNN-DDI, MACCSkeys, PubChem, DBP and
ATC feature descriptions of drugs were respectively concatenated to feed the MLP predictor
of GNN-DDI for DDI prediction. Figure 6 shows the AUCs and ACCs of GNN-DDI and
four other methods in the second DDI prediction scenario, from which we can see that
GNN-DDI achieved the best results.Molecules 2022 ,27, 3004 11 of 16
Molecules 2022 , 27, x FOR PEER REVIEW 11 of 17 
 
  
Figure 6. Comparison results of GNN-DDI with four ot her methods in the second DDI prediction 
scenario. 
3.4. Effects of Using Different  Feature Extraction Approaches 
The GNN-DDI feature extractor consists of  a five-layer GAT network to learn the 
latent feature vectors of drugs. In each layer, the convolutional operation aggregates 
information from its atomic neighborhood and updates the node feature for each atomic 
node in a drug molecular structure graph. Through several convolutional layers, we 
captured the informative features of drug chemical functional groups within the whole chemical structure. In order to evaluate the effectiveness of the molecular structure 
features learned by GNN-DDI, we compared these with two structure features derived 
from the PubChem fingerprint (named the PubChem feature) and MACCSkeys 
fingerprint feature (named the MACCSkeys feature), and the drug’s chemical and 
biological features according to DBP and ATC. These features were respectively 
concatenated to feed the MLP predictor of GNN-DDI for DDI prediction. 
The comparison results are shown in Table 2, from which we can see that the 
structure feature learned by the GNN-DDI feat ure extractor outperformed the other four 
features in terms of AUC, AUPR and recall. Sp ecifically, the structure feature learned by 
GNN-DDI achieved improvements of 0.6~4.8%, 0.2~5.5%, 0.4~11.7% against the other four 
features from the PubChem fingerprint, MACCS keys fingerprint, DBP, and ATC in terms 
of AUC, AUPR, recall, respectively. Although the precision, ACC, and F 1 of the structure 
feature learned by GNN-DDI are lower than those of the PubChem feature and MACCSkeys feature, the structure features ex tracted directly from the drug molecular 
graph by the five-layer GAT network in GNN- DDI can explore the specific substructures 
of drugs. This can improve interpretability and reveal the underlying mechanisms of drug 
pair interactions. 
Table 2. Comparison results of the structure features  learned by GNN-DDI and other chemical and 
biological features. 
 AUC  AUPR  Recall  Precision  ACC  F1 
Pubchem features  0.920 0.928 0.880 0.862 0.905 0.883 
MACCSkeys features 0.930 0.924 0.879 0.864 0.901 0.882 
DBP features 0.862 0.875 0.803 0.757 0.89 0.819 
ATC features 0.888 0.895 0.834 0.811 0.871 0.840 
GNN-DDI features 0.936 0.930 0.920 0.823 0.861 0.869 
  
Figure 6. Comparison results of GNN-DDI with four other methods in the second DDI
prediction scenario.
3.4. Effects of Using Different Feature Extraction Approaches
The GNN-DDI feature extractor consists of a ﬁve-layer GAT network to learn the latent
feature vectors of drugs. In each layer, the convolutional operation aggregates information
from its atomic neighborhood and updates the node feature for each atomic node in
a drug molecular structure graph. Through several convolutional layers, we captured
the informative features of drug chemical functional groups within the whole chemical
structure. In order to evaluate the effectiveness of the molecular structure features learned
by GNN-DDI, we compared these with two structure features derived from the PubChem
ﬁngerprint (named the PubChem feature) and MACCSkeys ﬁngerprint feature (named
the MACCSkeys feature), and the drug’s chemical and biological features according to
DBP and ATC. These features were respectively concatenated to feed the MLP predictor of
GNN-DDI for DDI prediction.
The comparison results are shown in Table 2, from which we can see that the structure
feature learned by the GNN-DDI feature extractor outperformed the other four features in
terms of AUC, AUPR and recall. Speciﬁcally, the structure feature learned by GNN-DDI
achieved improvements of 0.6~4.8%, 0.2~5.5%, 0.4~11.7% against the other four features
from the PubChem ﬁngerprint, MACCSkeys ﬁngerprint, DBP , and ATC in terms of AUC,
AUPR, recall, respectively. Although the precision, ACC, and F 1of the structure feature
learned by GNN-DDI are lower than those of the PubChem feature and MACCSkeys
feature, the structure features extracted directly from the drug molecular graph by the ﬁve-
layer GAT network in GNN-DDI can explore the speciﬁc substructures of drugs. This can
improve interpretability and reveal the underlying mechanisms of drug pair interactions.
Table 2. Comparison results of the structure features learned by GNN-DDI and other chemical and
biological features.
AUC AUPR Recall Precision ACC F 1
Pubchem features 0.920 0.928 0.880 0.862 0.905 0.883
MACCSkeys features 0.930 0.924 0.879 0.864 0.901 0.882
DBP features 0.862 0.875 0.803 0.757 0.89 0.819
ATC features 0.888 0.895 0.834 0.811 0.871 0.840
GNN-DDI features 0.936 0.930 0.920 0.823 0.861 0.869
3.5. Interpretability Case Studies
In this section, we will explore the speciﬁc substructures of drugs that result in po-
tential DDIs. Different layers of graph convolutional network involved various neighbor
receptive ﬁelds of the drug molecular graph. The ﬁve k-hop latent feature vectors H(k)
Gxof
each drug contained various sizes of sub-structures in its molecular graph. We reservedMolecules 2022 ,27, 3004 12 of 16
these k-hop latent feature vectorsn
H(k)
GxoK
k=1andn
H(k)
GyoK
k=1of each drug pair from dif-
ferent layers of the feature extractor in GNN-DDI, and selected the two features with the
largest scores as the most contributing substructure features to the potential interaction of
this drug pair.
Score =MAX
H(k)
GxH(k)
GyT
,i=1, 2, . . . , K;j=1, 2, . . . , K (11)
where K=5and “ . . .” denotes the inner product operation. The larger the inner product
value, the greater the contribution of substructure features to the potential interaction of
this drug pair. The k-hop latent feature vector H(k)
Gxwas derived from the atomic feature
matrix H(k)
iin the drug molecular graph Gxby SAGPooling [ 49] (Equation (4)). The feature
weight of each atomic node iin the pooling process represents the importance of each
node in the molecular graph, and is determined according to the topological and contextual
information of the node in the drug molecular graph Gxby SAGPooling. According to the
atomic weight iin feature vectors H(s)
GxandH(t)
Gy, we drew the weighted molecular structure
graphs of two drugs Gxand Gyto illustrate the speciﬁc substructures that contribute to
potential interaction of drug pair ( Gx,Gy), and help to discover the underlying mechanisms
of DDIs.
We selected three interactions between Sildenaﬁl and other nitrate-based drugs (Isosor-
bide mononitrate, Nitroglycerin, Amyl Nitrite) as a case study [ 55]. Sildenaﬁl is an effective
treatment for erectile dysfunction and pulmonary hypertension [ 56]. Sildenaﬁl was devel-
oped as a phosphodiesterase-5 (PDE5) inhibitor. In the presence of a PDE5 inhibitor, nitrate
(NOO3)-based drugs such as Isosorbide mononitrate can cause dramatic increases in cyclic
guanosine monophosphate [ 57] (Murad 1986), which leads to intense lowering of blood
pressure that can cause heart attacks [58].
We drew the heat map of the weighted molecular structure graphs for each drug pair
according to the atomic weight iin feature vectors H(s)
Gxand H(t)
Gy(Figure 6). Each row in
Figure 7 contains a pair of drugs and the descriptions of corresponding interactions. In the
heat map, the important contributing substructures are mainly concentrated near its center
(represented by green circles). From the heat map, we can see that the speciﬁc substructure
of the nitrate group (NOO3) contributes highly to the interaction between Sildenaﬁl and
other nitrate-based drugs (Isosorbide Mononitrate, Nitroglycerin, Amyl Nitrite).Molecules 2022 ,27, 3004 13 of 16
Molecules 2022 , 27, x FOR PEER REVIEW 13 of 17 
 
   
(a) 
  
(b) 
  
(c) 
Figure 7. Contributions of specific substructures to drug interactions. ( a) Sildenafil (k = 4) and Iso-
sorbide Mononitrate (k = 3). Description in DrugBa nk: The risk or severity of hypotension can be 
increased when Isosorbide mononitrat e is combined with Sildenafil. ( b) Sildenafil (k = 4) and Nitro-
glycerin (k = 3). Description in Dr ugBank: The risk or severity of hypotension can be increased when 
Figure 7. Contributions of speciﬁc substructures to drug interactions. ( a) Sildenaﬁl (k = 4) and
Isosorbide Mononitrate (k = 3). Description in DrugBank: The risk or severity of hypotension can
be increased when Isosorbide mononitrate is combined with Sildenaﬁl. ( b) Sildenaﬁl (k = 4) and
Nitroglycerin (k = 3). Description in DrugBank: The risk or severity of hypotension can be increased
when Nitroglycerin is combined with Sildenaﬁl. ( c) Sildenaﬁl (k = 4) and Amyl Nitrite (k = 3).
Description in DrugBank: The risk or severity of hypotension can be increased when Amyl Nitrite is
combined with Sildenaﬁl.Molecules 2022 ,27, 3004 14 of 16
4. Conclusions
Aiming to address the problem that current DDI prediction methods are incapable
of predicting potential interactions for new drugs and always lack interpretability, we
proposed a novel method GNN-DDI to predict potential DDIs by constructing a ﬁve-layer
graph attention network (GAT) to learn k-hops low-dimensional feature representations
of each drug from its chemical molecular graph. The learned features of each drug pair
were concatenated, and fed into an MLP to output the ﬁnal DDI prediction score. The
multi-layer GAT of GNN-DDI can capture different kth-order substructure functional
groups of the drug molecular graph through multi-step operations, to generate the effective
feature representation of drugs. The experimental results demonstrate that GNN-DDI
achieved superior performance in each of two DDI predicting scenarios, namely potential
DDIs among known drugs and between known drugs and new drugs. In addition, the
performance of drug features directly learned by GNN-DDI from drug chemical molecular
graphs is better than that obtained from drug chemical structure ﬁngerprints, biological
features and ATC features, which proves the feature effectiveness derived from our method.
In the case study we selected three interactions between Sildenaﬁl and other nitrate-based
drugs, which lead to intense lowering of blood pressure that can cause heart attacks. More
importantly, the result shows that our GNN-DDI can explore speciﬁc drug substructures
that can result in potential DDIs, helping to improve interpretability and to discover the
underlying interaction mechanisms of drug pairs.
Author Contributions: Methodology, data curation, writing—original draft preparation: Y.-H.F.
writing—review and editing, funding acquisition: S.-W.Z. All authors have read and agreed to the
published version of the manuscript.
Funding: This work has been supported by the National Natural Science Foundation of China (grant
numbers,62173271, 61873202, PI: Zhang, S.-W.).
Institutional Review Board Statement: Not applicable.
Informed Consent Statement: Not applicable.
Data Availability Statement: The source code and associated datasets used in this work are publicly
available at https://github.com/NWPU-903PR/GNN-DDI (accessed on 7 April 2022).
Acknowledgments: We acknowledge anonymous reviewers for the valuable comments on the
original manuscript.
Conﬂicts of Interest: None of the authors has any competing interest.
Abbreviations
DDIs Drug-Drug Interactions
GAT Graph Attention Network
MLP Multi-Layer Perception
MACCSkeys Molecular ACCess System keys
ATC Anatomical Therapeutic Chemical classiﬁcation
DBP Drug-Binding Protein
AUC Area Under the receiver operating characteristic Curve
AUPR Area Under the Precision-Recall curve
ACC ACCuracy
References
1. Cheng, F.; Kov ács, I.A.; Barab ási, A.L. Network-based prediction of drug combinations. Nat. Commun. 2019 ,10, 1197. [CrossRef]
[PubMed]
2. Zhu, A.X.; Finn, R.S.; Edeline, J.; Cattan, S.; Ogasawara, S.; Palmer, D.; Verslype, C.; Zagonel, V .; Fartoux, L.; Vogel, A.; et al.
Pembrolizumab in patients with advanced hepatocellular carcinoma previously treated with sorafenib (KEYNOTE-224): A
non-randomised, open-label phase 2 trial. Lancet Oncol. 2018 ,19, 940–952. [CrossRef]
3. Entacapone/levodopa/carbidopa combination tablet: Stalevo. Drugs R&D 2003 ,4, 310–311. [CrossRef]Molecules 2022 ,27, 3004 15 of 16
4. Niu, J.; Straubinger, R.M.; Mager, D.E. Pharmacodynamic Drug-Drug Interactions. Clin. Pharmacol. Ther. 2019 ,105, 1395–1406.
[CrossRef]
5. Sun, M.; Zhao, S.; Gilvary, C.; Elemento, O.; Zhou, J.; Wang, F. Graph convolutional networks for computational drug development
and discovery. Brief. Bioinform. 2020 ,21, 919–935. [CrossRef]
6. Pathak, J.; Kiefer, R.C.; Chute, C.G. Using linked data for mining drug-drug interactions in electronic health records. Stud. Health
Technol. Inf. 2013 ,192, 682.
7. Duke, J.D.; Han, X.; Wang, Z.; Subhadarshini, A.; Karnik, S.D.; Li, X.; Hall, S.D.; Jin, Y.; Callaghan, J.T.; Overhage, M.J.; et al.
Literature Based Drug Interaction Prediction with Clinical Assessment Using Electronic Medical Records: Novel Myopathy
Associated Drug Interactions. PLoS Comput. Biol. 2012 ,8, e1002614. [CrossRef]
8. Bui, Q.C.; Sloot, P .M.; Van Mulligen, E.M.; Kors, J.A. A novel feature-based approach to extract drug-drug interactions from
biomedical text. Bioinformatics 2014 ,30, 3365–3371. [CrossRef]
9. Abacha, A.B.; Chowdhury, M.F.M.; Karanasiou, A.; Mrabet, Y.; Lavelli, A.; Zweigenbaum, P . Text mining for pharmacovigilance:
Using machine learning for drug name recognition and drug–drug interaction extraction and classiﬁcation. J. Biomed. Inform.
2015 ,58, 122–132. [CrossRef]
10. Cai, R.; Liu, M.; Hu, Y.; Melton, B.L.; Matheny, M.; Xu, H.; Duan, L.; Waitman, L.R. Identiﬁcation of adverse drug-drug interactions
through causal association rule discovery from spontaneous adverse event reports. Artif. Intell. Med. 2017 ,76, 7–15. [CrossRef]
11. Vilar, S.; Friedman, C.; Hripcsak, G. Detection of drug–drug interactions through data mining studies using clinical sources,
scientiﬁc literature and social media. Brief. Bioinform. 2018 ,19, 863–877. [CrossRef] [PubMed]
12. Zhang, T.; Leng, J.; Liu, Y. Deep learning for drug–drug interaction extraction from the literature: A review. Brief. Bioinform. 2020 ,
21, 1609–1627. [CrossRef] [PubMed]
13. Zhang, Y.; Zheng, W.; Lin, H.; Wang, J.; Yang, Z.; Dumontier, M. Drug-drug Interaction Extraction via Hierarchical RNNs on
Sequence and Shortest Dependency Paths. Bioinformatics 2018 ,34, 828–835. [CrossRef] [PubMed]
14. Takeda, T.; Hao, M.; Cheng, T.; Bryant, S.H.; Wang, Y. Predicting drug–drug interactions through drug structural similarities and
interaction networks incorporating pharmacokinetics and pharmacodynamics knowledge. J. Chemin 2017 ,9, 16. [CrossRef]
15. Zhang, W.; Chen, Y.; Liu, F.; Luo, F.; Tian, G.; Li, X. Predicting potential drug-drug interactions by integrating chemical, biological,
phenotypic and network data. BMC Bioinform. 2017 ,18, 18. [CrossRef]
16. Kastrin, A.; Ferk, P .; Leskošek, B. Predicting potential drug-drug interactions on topological and semantic similarity features
using statistical learning. PLoS ONE 2018 ,13, e0196865. [CrossRef]
17. Yu, H.; Mao, K.-T.; Shi, J.-Y.; Huang, H.; Chen, Z.; Dong, K.; Yiu, S.-M. Predicting and understanding comprehensive drug-drug
interactions via semi-nonnegative matrix factorization. BMC Syst. Biol. 2018 ,12, 101–110. [CrossRef]
18. Zhang, S. SFLLN: A sparse feature learning ensemble method with linear neighborhood regularization for predicting drug–drug
interactions. Inf. Sci. 2019 ,497, 189–201. [CrossRef]
19. Sridhar, D.; Fakhraei, S.; Getoor, L. A probabilistic approach for collective similarity-based drug–drug interaction prediction.
Bioinform. 2016 ,32, 3175–3182. [CrossRef]
20. Gottlieb, A.; Stein, G.Y.; Oron, Y.; Ruppin, E.; Sharan, R. INDI: A computational framework for inferring drug interactions and
their associated recommendations. Mol. Syst. Biol. 2012 ,8, 592. [CrossRef]
21. Cheng, F.; Zhao, Z. Machine learning-based prediction of drug–drug interactions by integrating drug phenotypic, therapeutic,
chemical, and genomic properties. J. Am. Med Inform. Assoc. 2014 ,21, e278–e286. [CrossRef]
22. Feng, Y.-H.; Zhang, S.-W.; Shi, J.-Y. DPDDI: A deep predictor for drug-drug interactions. BMC Bioinform. 2020 ,21, 419. [CrossRef]
[PubMed]
23. Zhang, P .; Wang, F.; Hu, J.; Sorrentino, R. Label Propagation Prediction of Drug-Drug Interactions Based on Clinical Side Effects.
Sci. Rep. 2015 ,5, 12339. [CrossRef] [PubMed]
24. Rohani, N.; Eslahchi, C.; Katanforoush, A. ISCMF: Integrated similarity-constrained matrix factorization for drug–drug interaction
prediction. Netw. Model. Anal. Health Inform. Bioinform. 2020 ,9, 11. [CrossRef]
25. Wu, Z.; Pan, S.; Chen, F.; Long, G.; Zhang, C.; Yu, P .S. A comprehensive survey on graph neural networks. arXiv 2019 ,
arXiv:1901.00596. Available online: https://arxiv.org/abs/1901.00596 (accessed on 4 September 2021). [CrossRef] [PubMed]
26. Gao, K.Y.; Fokoue, A.; Luo, H.; Iyengar, A.; Dey, S.; Zhang, P . Interpretable Drug Target Prediction Using Deep Neural
Representation. In Proceedings of the Twenty-Seventh International Joint Conference on Artiﬁcial Intelligence, Stockholm,
Sweden, 13–19 July 2018; pp. 3371–3377. [CrossRef]
27. Han, L.; Sayyid, Z.N.; Altman, R.B. Modeling drug response using network-based personalized treatment prediction (NetPTP)
with applications to inﬂammatory bowel disease. PLoS Comput. Biol. 2021 ,17, e1008631. [CrossRef]
28. Yang, J.; Li, A.; Li, Y.; Guo, X.; Wang, M. A novel approach for drug response prediction in cancer cell lines via network
representation learning. Bioinformatics 2018 ,35, 1527–1535. [CrossRef] [PubMed]
29. Le, D.H.; Pham, V .H. Drug Response Prediction by Globally Capturing Drug and Cell Line Information in a Heterogeneous
Network. J. Mol. Biol. 2018 ,430, 2993–3004. [CrossRef]
30. Jia, P .; Hu, R.; Pei, G.; Dai, Y.; Wang, Y.-Y.; Zhao, Z. Deep generative neural network for accurate drug response imputation. Nat.
Commun. 2021 ,12, 1740. [CrossRef]
31. Gerdes, H.; Casado, P .; Dokal, A.; Hijazi, M.; Akhtar, N.; Osuntola, R.; Rajeeve, V .; Fitzgibbon, J.; Travers, J.; Britton, D.; et al. Drug
ranking using machine learning systematically predicts the efﬁcacy of anti-cancer drugs. Nat. Commun. 2021 ,12, 1850. [CrossRef]Molecules 2022 ,27, 3004 16 of 16
32. Yu, L.; Xia, M.; An, Q. A network embedding framework based on integrating multiplex network for drug combination prediction.
Brief. Bioinform. 2021 ,23, 364. [CrossRef] [PubMed]
33. Liu, Q.; Xie, L. TranSynergy: Mechanism-driven interpretable deep neural network for the synergistic prediction and pathway
deconvolution of drug combinations. PLoS Comput. Biol. 2021 ,17, e1008653. [CrossRef] [PubMed]
34. Karimi, M.; Hasanzadeh, A.; Shen, Y. Network-principled deep generative models for designing drug combinations as graph sets.
Bioinformatics 2020 ,36, i445–i454. [CrossRef] [PubMed]
35. Huang, L.; Brunell, D.; Stephan, C.; Mancuso, J.; Yu, X.; He, B.; Thompson, T.C.; Zinner, R.; Kim, J.; Davies, P .; et al. Driver
network as a biomarker: Systematic integration and network modeling of multi-omics data to derive driver signaling pathways
for drug combination prediction. Bioinformatics 2019 ,35, 3709–3717. [CrossRef]
36. Fokoue, A.; Sadoghi, M.; Hassanzadeh, O.; Zhang, P . Predicting Drug-Drug Interactions Through Large-Scale Similarity-Based
Link Prediction. In Lecture Notes in Computer Science ; Springer: Cham, Switzerland, 2016; pp. 774–789.
37. Ryu, J.Y.; Kim, H.U.; Lee, S.Y. Deep learning improves prediction of drug-drug and drug-food interactions. Proc. Natl. Acad. Sci.
USA 2018 ,115, E4304–E4311. [CrossRef]
38. Lee, G.; Park, C.; Ahn, J. Novel deep learning model for more accurate prediction of drug-drug interaction effects. BMC Bioinform.
2019 ,20, 415. [CrossRef]
39. Deng, Y.; Xu, X.; Qiu, Y.; Xia, J.; Zhang, W.; Liu, S. A multimodal deep learning framework for predicting drug–drug interaction
events. Bioinformatics 2020 ,36, 4316–4322. [CrossRef]
40. Nyamabo, A.K.; Yu, H.; Shi, J.Y. SSI-DDI: Substructure-substructure interactions for drug-drug interaction prediction. Brief
Bioinform 2021 ,22, bbab133. [CrossRef]
41. Liu, S.; Huang, Z.; Qiu, Y.; Chen, Y.-P .P .; Zhang, W. Structural Network Embedding using Multi-modal Deep Auto-encoders for
Predicting Drug-drug Interactions. In Proceedings of the 2019 IEEE International Conference on Bioinformatics and Biomedicine
(BIBM), San Diego, CA, USA, 18–21 November 2019; pp. 445–450.
42. Wang, F.; Lei, X.; Liao, B.; Wu, F.-X. Predicting drug–drug interactions by graph convolutional network with multi-kernel. Brief.
Bioinform. 2021 , 23. [CrossRef]
43. Rohani, N.; Eslahchi, C. Drug-Drug Interaction Predicting by Neural Network Using Integrated Similarity. Sci. Rep. 2019 ,9, 13645.
[CrossRef]
44. Lin, X.; Quan, Z.; Wang, Z.J.; Ma, T.; Zeng, X. KGNN: Knowledge Graph Neural Network for Drug-Drug Interaction Prediction.
In IJCAI. Available online: https://www.ijcai.org/proceedings/2020/380 (accessed on 11 September 2021).
45. Wishart, D.S.; Feunang, Y.D.; Guo, A.C.; Lo, E.J.; Marcu, A.; Grant, J.R.; Sajed, T.; Johnson, D.; Li, C.; Sayeeda, Z.; et al. DrugBank
5.0: A Major Update to the DrugBank Database for 2018. Nucleic Acids Res. 2018 ,46, D1074–D1082. [CrossRef] [PubMed]
46. Rogers, D.; Hahn, M. Extended-Connectivity Fingerprints. J. Chem. Inf. Model. 2010 ,50, 742–754. [CrossRef] [PubMed]
47. Skrbo, A.; Begovi´ c, B.; Skrbo, S. [Classiﬁcation of drugs using the ATC system (Anatomic, Therapeutic, Chemical Classiﬁcation)
and the latest changes]. Med. Arh. 2004 ,58, 138–141. [PubMed]
48. Shi, J.-Y.; Mao, K.-T.; Yu, H.; Yiu, S.-M. Detecting drug communities and predicting comprehensive drug–drug interactions via
balance regularized semi-nonnegative matrix factorization. J. Cheminform. 2019 ,11, 1–16. [CrossRef] [PubMed]
49. Veliˇ ckovi´ c, P .; Cucurull, G.; Casanova, A.; Romero, A.; Lio, P .; Bengio, Y. Graph attention networks. arXiv 2017 , arXiv:1710.10903.
Available online: https://arxiv.org/abs/1710.10903 (accessed on 1 January 2020).
50. Lee, J.; Lee, I.; Kang, J. Self-Attention Graph Pooling. ICML, 2019: P . 6661–70. Available online: https://proceedings.mlr.press/v9
7/lee19c.html (accessed on 4 January 2020).
51. Maas, A.L.; Hannun, A.Y.; Ng, A.Y. Rectiﬁer Nonlinearities Improve Neural Network Acoustic Models. in Proc. Icml. Citeseer.
2013. Available online: https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.693.1422&rep=rep1&type=pdf (accessed on
1 January 2020).
52. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A.N.; Polosukhin, I. Attention Is All You Need. Adv. Neural
Inf. Process. Syst. 2017 ,30, 5998–6008.
53. Kingma, D.P .; Ba, J. Adam: A method for stochastic optimization. In Proceedings of the International Conference Learn, Represent.
(ICLR), San Diego, CA, USA, 5–8 May 2015; Available online: https://arxiv.org/abs/1412.6980 (accessed on 1 September 2021).
54. Vilar, S.; Harpaz, R.; Uriarte, E.; Santana, L.; Rabadan, R.; Friedman, C. Drug—drug interaction through molecular structure
similarity analysis. J. Am. Med Inform. Assoc. 2012 ,19, 1066–1074. [CrossRef]
55. Huang, K.; Xiao, C.; Hoang, T.; Glass, L.; Sun, J. CASTER: Predicting Drug Interactions with Chemical Substructure Representation.
arXiv 2019 , arXiv:1911.06446. Available online: https://ojs.aaai.org/index.php/AAAI/article/view/5412 (accessed on 1 January
2020). [CrossRef]
56. Bhogal, S.; Khraisha, O.; Al Madani, M.; Treece, J.; Baumrucker, S.J.; Paul, T.K. Sildenaﬁl for Pulmonary Arterial Hypertension.
Am. J. Ther. 2019 ,26, e520–e526. [CrossRef]
57. Murad, F. Cyclic guanosine monophosphate as a mediator of vasodilation. J. Clin. Investig. 1986 ,78, 1–5. [CrossRef]
58. Ishikura, F.; Beppu, S.; Hamada, T.; Khandheria, B.K.; Seward, J.B.; Nehra, A. Effects of sildenaﬁl citrate (Viagra) combined with
nitrate on the heart. Circulation 2000 ,102, 2516–2521. [CrossRef] [PubMed]